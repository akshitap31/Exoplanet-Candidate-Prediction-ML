{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>1.846000e-04</td>\n",
       "      <td>-1.846000e-04</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-152</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>-1.160000e-07</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>-166</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>...</td>\n",
       "      <td>-220</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>2.430000e-06</td>\n",
       "      <td>-2.430000e-06</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>6.360000e-05</td>\n",
       "      <td>-6.360000e-05</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>-225</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0          CONFIRMED              0              0              0   \n",
       "1     FALSE POSITIVE              0              1              0   \n",
       "2     FALSE POSITIVE              0              1              0   \n",
       "3          CONFIRMED              0              0              0   \n",
       "4          CONFIRMED              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "6986  FALSE POSITIVE              0              0              0   \n",
       "6987  FALSE POSITIVE              0              1              1   \n",
       "6988       CANDIDATE              0              0              0   \n",
       "6989  FALSE POSITIVE              0              0              1   \n",
       "6990  FALSE POSITIVE              0              0              1   \n",
       "\n",
       "      koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  \\\n",
       "0                 0   54.418383     2.479000e-04    -2.479000e-04   \n",
       "1                 0   19.899140     1.490000e-05    -1.490000e-05   \n",
       "2                 0    1.736952     2.630000e-07    -2.630000e-07   \n",
       "3                 0    2.525592     3.760000e-06    -3.760000e-06   \n",
       "4                 0    4.134435     1.050000e-05    -1.050000e-05   \n",
       "...             ...         ...              ...              ...   \n",
       "6986              1    8.589871     1.846000e-04    -1.846000e-04   \n",
       "6987              0    0.527699     1.160000e-07    -1.160000e-07   \n",
       "6988              0    1.739849     1.780000e-05    -1.780000e-05   \n",
       "6989              0    0.681402     2.430000e-06    -2.430000e-06   \n",
       "6990              1    4.856035     6.360000e-05    -6.360000e-05   \n",
       "\n",
       "      koi_time0bk  koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  \\\n",
       "0      162.513840          0.003520  ...             -81      4.467   \n",
       "1      175.850252          0.000581  ...            -176      4.544   \n",
       "2      170.307565          0.000115  ...            -174      4.564   \n",
       "3      171.595550          0.001130  ...            -211      4.438   \n",
       "4      172.979370          0.001900  ...            -232      4.486   \n",
       "...           ...               ...  ...             ...        ...   \n",
       "6986   132.016100          0.015700  ...            -152      4.296   \n",
       "6987   131.705093          0.000170  ...            -166      4.529   \n",
       "6988   133.001270          0.007690  ...            -220      4.444   \n",
       "6989   132.181750          0.002850  ...            -236      4.447   \n",
       "6990   135.993300          0.010800  ...            -225      4.385   \n",
       "\n",
       "      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n",
       "0              0.064          -0.096     0.927          0.105         -0.061   \n",
       "1              0.044          -0.176     0.868          0.233         -0.078   \n",
       "2              0.053          -0.168     0.791          0.201         -0.067   \n",
       "3              0.070          -0.210     1.046          0.334         -0.133   \n",
       "4              0.054          -0.229     0.972          0.315         -0.105   \n",
       "...              ...             ...       ...            ...            ...   \n",
       "6986           0.231          -0.189     1.088          0.313         -0.228   \n",
       "6987           0.035          -0.196     0.903          0.237         -0.079   \n",
       "6988           0.056          -0.224     1.031          0.341         -0.114   \n",
       "6989           0.056          -0.224     1.041          0.341         -0.114   \n",
       "6990           0.054          -0.216     1.193          0.410         -0.137   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "0     291.93423  48.141651      15.347  \n",
       "1     297.00482  48.134129      15.436  \n",
       "2     285.53461  48.285210      15.597  \n",
       "3     288.75488  48.226200      15.509  \n",
       "4     296.28613  48.224670      15.714  \n",
       "...         ...        ...         ...  \n",
       "6986  298.74921  46.973351      14.478  \n",
       "6987  297.18875  47.093819      14.082  \n",
       "6988  286.50937  47.163219      14.757  \n",
       "6989  294.16489  47.176281      15.385  \n",
       "6990  297.00977  47.121021      14.826  \n",
       "\n",
       "[6991 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X= df.drop(columns = ['koi_disposition'])\n",
    "y = df['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.11345814045880986, 'koi_fpflag_co'),\n",
       " (0.101224083730834, 'koi_fpflag_nt'),\n",
       " (0.06957323390620054, 'koi_fpflag_ss'),\n",
       " (0.05428927090186432, 'koi_model_snr'),\n",
       " (0.05082702248767769, 'koi_prad'),\n",
       " (0.03671053006815837, 'koi_fpflag_ec'),\n",
       " (0.03428482387461765, 'koi_duration_err1'),\n",
       " (0.03176741802003541, 'koi_duration_err2'),\n",
       " (0.03088459630847872, 'koi_prad_err1'),\n",
       " (0.029325670175726216, 'koi_steff_err1'),\n",
       " (0.028799352584748222, 'koi_prad_err2'),\n",
       " (0.026206297713796397, 'koi_steff_err2'),\n",
       " (0.023933529567390026, 'koi_time0bk_err1'),\n",
       " (0.023313305717169452, 'koi_duration'),\n",
       " (0.02308501623161511, 'koi_time0bk_err2'),\n",
       " (0.020636795308044787, 'koi_period'),\n",
       " (0.020037201126070943, 'koi_depth'),\n",
       " (0.018673807842494818, 'koi_impact'),\n",
       " (0.018057318146845504, 'koi_period_err2'),\n",
       " (0.01780540096516545, 'koi_period_err1'),\n",
       " (0.017348338708865832, 'koi_insol_err1'),\n",
       " (0.01585116357943383, 'koi_insol'),\n",
       " (0.015658114677505483, 'koi_teq'),\n",
       " (0.014998358136256093, 'koi_depth_err1'),\n",
       " (0.014247289017490287, 'koi_depth_err2'),\n",
       " (0.013072942387597252, 'koi_time0bk'),\n",
       " (0.013031963465359472, 'koi_insol_err2'),\n",
       " (0.012944566784915465, 'koi_srad_err1'),\n",
       " (0.011869219173261813, 'ra'),\n",
       " (0.010651743375637308, 'dec'),\n",
       " (0.010484475983293353, 'koi_kepmag'),\n",
       " (0.010312887204666419, 'koi_impact_err1'),\n",
       " (0.010050583692150516, 'koi_impact_err2'),\n",
       " (0.009352128921156971, 'koi_steff'),\n",
       " (0.00932997545726869, 'koi_slogg'),\n",
       " (0.009237572754024842, 'koi_srad'),\n",
       " (0.008892779698446679, 'koi_slogg_err2'),\n",
       " (0.00824590425728712, 'koi_srad_err2'),\n",
       " (0.008195485478924224, 'koi_slogg_err1'),\n",
       " (0.003331692110715015, 'koi_tce_plnt_num')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "# fits random forest model to X and y\n",
    "rf = rf.fit(X, y)\n",
    "# returns the importance of each column to predicting the outcomes\n",
    "importances = rf.feature_importances_\n",
    "sorted(zip(importances, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with importance > 3% are selected\n",
    "X = df[[\"koi_fpflag_co\", \"koi_fpflag_nt\", \"koi_fpflag_ss\", \"koi_model_snr\", \"koi_prad\", \"koi_prad_err1\", \"koi_fpflag_ec\", \"koi_prad_err2\", \"koi_duration_err1\", \"koi_duration_err2\", \"koi_steff_err1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>-0.1530</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>14.59</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>-0.0152</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-0.1650</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>-0.9390</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_co  koi_fpflag_nt  koi_fpflag_ss  koi_model_snr  koi_prad  \\\n",
       "3563              0              0              0           11.7      3.89   \n",
       "4099              0              0              0           18.0      2.10   \n",
       "5460              0              0              0          476.0     14.59   \n",
       "1091              0              0              0           34.7      2.28   \n",
       "5999              0              0              0            8.7      2.27   \n",
       "\n",
       "      koi_prad_err1  koi_fpflag_ec  koi_prad_err2  koi_duration_err1  \\\n",
       "3563           0.65              0          -0.34             0.1430   \n",
       "4099           0.14              0          -0.20             0.1530   \n",
       "5460           1.15              0          -1.28             0.0152   \n",
       "1091           0.32              0          -0.20             0.1650   \n",
       "5999           1.27              0          -0.54             0.9390   \n",
       "\n",
       "      koi_duration_err2  koi_steff_err1  \n",
       "3563            -0.1430             120  \n",
       "4099            -0.1530             144  \n",
       "5460            -0.0152             126  \n",
       "1091            -0.1650             101  \n",
       "5999            -0.9390             164  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test =  scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-(I) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter Tuning using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\" : [10, 50, 100, 200],\n",
    "\"max_depth\" : [3, 10, 20, 40]}\n",
    "grid = GridSearchCV(rf_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=10, score=0.847, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=10, score=0.883, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=10, score=0.869, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=10, score=0.857, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=10, score=0.825, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=3, n_estimators=50, score=0.852, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=50, score=0.874, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=50, score=0.858, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=50, score=0.836, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ........ max_depth=3, n_estimators=50, score=0.848, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=100, score=0.832, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=100, score=0.854, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=100, score=0.868, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=100, score=0.852, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=100, score=0.855, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=200, score=0.861, total=   0.5s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=200, score=0.874, total=   0.5s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=200, score=0.862, total=   0.5s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=200, score=0.854, total=   0.5s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=3, n_estimators=200, score=0.851, total=   0.5s\n",
      "[CV] max_depth=10, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=10, score=0.889, total=   0.0s\n",
      "[CV] max_depth=10, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=10, score=0.889, total=   0.0s\n",
      "[CV] max_depth=10, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=10, score=0.889, total=   0.0s\n",
      "[CV] max_depth=10, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=10, score=0.885, total=   0.0s\n",
      "[CV] max_depth=10, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=10, score=0.869, total=   0.0s\n",
      "[CV] max_depth=10, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=50, score=0.888, total=   0.2s\n",
      "[CV] max_depth=10, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=50, score=0.888, total=   0.2s\n",
      "[CV] max_depth=10, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=50, score=0.888, total=   0.2s\n",
      "[CV] max_depth=10, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=50, score=0.884, total=   0.2s\n",
      "[CV] max_depth=10, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=10, n_estimators=50, score=0.868, total=   0.2s\n",
      "[CV] max_depth=10, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=100, score=0.889, total=   0.4s\n",
      "[CV] max_depth=10, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=100, score=0.891, total=   0.4s\n",
      "[CV] max_depth=10, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=100, score=0.888, total=   0.4s\n",
      "[CV] max_depth=10, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=100, score=0.885, total=   0.4s\n",
      "[CV] max_depth=10, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=100, score=0.868, total=   0.4s\n",
      "[CV] max_depth=10, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=200, score=0.885, total=   0.8s\n",
      "[CV] max_depth=10, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=200, score=0.894, total=   0.8s\n",
      "[CV] max_depth=10, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=200, score=0.888, total=   0.8s\n",
      "[CV] max_depth=10, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=200, score=0.885, total=   0.8s\n",
      "[CV] max_depth=10, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=10, n_estimators=200, score=0.867, total=   0.8s\n",
      "[CV] max_depth=20, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=10, score=0.870, total=   0.1s\n",
      "[CV] max_depth=20, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=10, score=0.871, total=   0.1s\n",
      "[CV] max_depth=20, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=10, score=0.878, total=   0.0s\n",
      "[CV] max_depth=20, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=10, score=0.884, total=   0.1s\n",
      "[CV] max_depth=20, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=10, score=0.865, total=   0.1s\n",
      "[CV] max_depth=20, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=50, score=0.882, total=   0.2s\n",
      "[CV] max_depth=20, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=50, score=0.874, total=   0.2s\n",
      "[CV] max_depth=20, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=50, score=0.888, total=   0.2s\n",
      "[CV] max_depth=20, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=50, score=0.887, total=   0.2s\n",
      "[CV] max_depth=20, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=20, n_estimators=50, score=0.870, total=   0.2s\n",
      "[CV] max_depth=20, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=100, score=0.885, total=   0.5s\n",
      "[CV] max_depth=20, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=100, score=0.882, total=   0.5s\n",
      "[CV] max_depth=20, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=100, score=0.889, total=   0.5s\n",
      "[CV] max_depth=20, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=100, score=0.892, total=   0.5s\n",
      "[CV] max_depth=20, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=100, score=0.868, total=   0.5s\n",
      "[CV] max_depth=20, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=200, score=0.888, total=   0.9s\n",
      "[CV] max_depth=20, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=200, score=0.883, total=   1.0s\n",
      "[CV] max_depth=20, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=200, score=0.891, total=   1.0s\n",
      "[CV] max_depth=20, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=200, score=0.897, total=   1.0s\n",
      "[CV] max_depth=20, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=20, n_estimators=200, score=0.867, total=   1.0s\n",
      "[CV] max_depth=40, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=10, score=0.867, total=   0.1s\n",
      "[CV] max_depth=40, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=10, score=0.872, total=   0.1s\n",
      "[CV] max_depth=40, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=10, score=0.879, total=   0.0s\n",
      "[CV] max_depth=40, n_estimators=10 ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... max_depth=40, n_estimators=10, score=0.878, total=   0.1s\n",
      "[CV] max_depth=40, n_estimators=10 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=10, score=0.859, total=   0.1s\n",
      "[CV] max_depth=40, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=50, score=0.875, total=   0.2s\n",
      "[CV] max_depth=40, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=50, score=0.884, total=   0.2s\n",
      "[CV] max_depth=40, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=50, score=0.883, total=   0.2s\n",
      "[CV] max_depth=40, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=50, score=0.890, total=   0.2s\n",
      "[CV] max_depth=40, n_estimators=50 ...................................\n",
      "[CV] ....... max_depth=40, n_estimators=50, score=0.865, total=   0.2s\n",
      "[CV] max_depth=40, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=100, score=0.886, total=   0.5s\n",
      "[CV] max_depth=40, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=100, score=0.879, total=   0.5s\n",
      "[CV] max_depth=40, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=100, score=0.888, total=   0.5s\n",
      "[CV] max_depth=40, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=100, score=0.894, total=   0.5s\n",
      "[CV] max_depth=40, n_estimators=100 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=100, score=0.866, total=   0.5s\n",
      "[CV] max_depth=40, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=200, score=0.886, total=   1.0s\n",
      "[CV] max_depth=40, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=200, score=0.879, total=   1.0s\n",
      "[CV] max_depth=40, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=200, score=0.890, total=   1.0s\n",
      "[CV] max_depth=40, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=200, score=0.895, total=   1.0s\n",
      "[CV] max_depth=40, n_estimators=200 ..................................\n",
      "[CV] ...... max_depth=40, n_estimators=200, score=0.865, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   29.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [3, 10, 20, 40],\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'n_estimators': 200}\n",
      "0.8851790873168921\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Model Results :-\n",
      "Training Data Score: 0.9941\n",
      "Testing Data Score: 0.8987\n"
     ]
    }
   ],
   "source": [
    "rf_model = grid.best_estimator_\n",
    "print(\"Random Forest Classifier Model Results :-\")\n",
    "print(f\"Training Data Score: {round(rf_model.score(X_train, y_train),4)}\")\n",
    "print(f\"Testing Data Score: {round(rf_model.score(X_test, y_test),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test =  scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50, 100, 150]}\n",
    "l_grid = GridSearchCV(classifier, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.836, total=   0.2s\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=1, score=0.827, total=   0.1s\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=1, score=0.806, total=   0.1s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.822, total=   0.1s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.822, total=   0.1s\n",
      "[CV] C=5 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=5, score=0.859, total=   0.1s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] ................................. C=5, score=0.848, total=   0.1s\n",
      "[CV] C=5 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=5, score=0.829, total=   0.1s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] ................................. C=5, score=0.832, total=   0.1s\n",
      "[CV] C=5 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=5, score=0.834, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ................................ C=10, score=0.856, total=   0.1s\n",
      "[CV] C=10 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=10, score=0.861, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ................................ C=10, score=0.834, total=   0.1s\n",
      "[CV] C=10 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=10, score=0.836, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ................................ C=10, score=0.845, total=   0.1s\n",
      "[CV] C=50 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=50, score=0.856, total=   0.1s\n",
      "[CV] C=50 ............................................................\n",
      "[CV] ................................ C=50, score=0.858, total=   0.1s\n",
      "[CV] C=50 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=50, score=0.846, total=   0.1s\n",
      "[CV] C=50 ............................................................\n",
      "[CV] ................................ C=50, score=0.841, total=   0.1s\n",
      "[CV] C=50 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=50, score=0.848, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................... C=100, score=0.860, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=100, score=0.863, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................... C=100, score=0.848, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=100, score=0.843, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................... C=100, score=0.849, total=   0.1s\n",
      "[CV] C=150 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=150, score=0.860, total=   0.1s\n",
      "[CV] C=150 ...........................................................\n",
      "[CV] ............................... C=150, score=0.865, total=   0.1s\n",
      "[CV] C=150 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=150, score=0.847, total=   0.1s\n",
      "[CV] C=150 ...........................................................\n",
      "[CV] ............................... C=150, score=0.841, total=   0.1s\n",
      "[CV] C=150 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=150, score=0.847, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\Anaconda3\\envs\\PythonAdvance\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 5, 10, 50, 100, 150]}, verbose=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100}\n",
      "0.8525627824391098\n"
     ]
    }
   ],
   "source": [
    "print(l_grid.best_params_)\n",
    "print(l_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Results :-\n",
      "Training Data Score: 0.8529\n",
      "Testing Data Score: 0.8696\n"
     ]
    }
   ],
   "source": [
    "classifier = l_grid.best_estimator_\n",
    "# classifier.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Model Results :-\")\n",
    "print(f\"Training Data Score: {round(classifier.score(X_train, y_train),4)}\")\n",
    "print(f\"Testing Data Score: {round(classifier.score(X_test, y_test),4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5243, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.834\n",
      "k: 3, Train/Test Score: 0.906/0.854\n",
      "k: 5, Train/Test Score: 0.891/0.862\n",
      "k: 7, Train/Test Score: 0.882/0.874\n",
      "k: 9, Train/Test Score: 0.881/0.877\n",
      "k: 11, Train/Test Score: 0.875/0.874\n",
      "k: 13, Train/Test Score: 0.874/0.873\n",
      "k: 15, Train/Test Score: 0.872/0.869\n",
      "k: 17, Train/Test Score: 0.869/0.867\n",
      "k: 19, Train/Test Score: 0.869/0.870\n",
      "k: 21, Train/Test Score: 0.868/0.870\n",
      "k: 23, Train/Test Score: 0.867/0.871\n",
      "k: 25, Train/Test Score: 0.869/0.872\n",
      "k: 27, Train/Test Score: 0.869/0.870\n",
      "k: 29, Train/Test Score: 0.870/0.872\n",
      "k: 31, Train/Test Score: 0.868/0.869\n",
      "k: 33, Train/Test Score: 0.866/0.869\n",
      "k: 35, Train/Test Score: 0.867/0.871\n",
      "k: 37, Train/Test Score: 0.868/0.871\n",
      "k: 39, Train/Test Score: 0.866/0.870\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbour Model Results (@ k=9) :- \n",
      "Training Data Score: 0.8806\n",
      "Testing Data Score: 0.877\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"K Nearest Neighbour Model Results (@ k=9) :- \")\n",
    "print(f\"Training Data Score: {round(knn.score(X_train, y_train),4)}\")\n",
    "print(f\"Testing Data Score: {round(knn.score(X_test, y_test),4)}\")\n",
    "# print('k=9 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(svm_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.833, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.824, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.802, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.813, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.821, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.833, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.824, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.802, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.813, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.821, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.833, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.824, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.802, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.813, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.821, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.833, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.824, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.802, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.813, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.821, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.847, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.834, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.815, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.830, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.829, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.847, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.834, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.815, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.830, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.829, total=   0.1s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.847, total=   0.1s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.834, total=   0.1s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.815, total=   0.1s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.830, total=   0.1s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.829, total=   0.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.847, total=   0.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.834, total=   0.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.815, total=   0.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.830, total=   0.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.829, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.849, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.851, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.835, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.825, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.841, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.849, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.851, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.835, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.825, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.841, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.849, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.851, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.835, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.825, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.841, total=   0.1s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.849, total=   0.1s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.851, total=   0.1s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.835, total=   0.1s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.825, total=   0.1s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.841, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.856, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, gamma=0.0001, score=0.865, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.851, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.844, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.850, total=   0.1s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.856, total=   0.1s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.865, total=   0.1s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.851, total=   0.1s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.844, total=   0.1s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.850, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.856, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.865, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.851, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.844, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.850, total=   0.1s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.856, total=   0.1s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.865, total=   0.1s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.851, total=   0.1s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.844, total=   0.1s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.850, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10, 50],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.0001}\n",
      "0.853325959292383\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Model Results :- \n",
      "Training Data Score: 0.8545\n",
      "Testing Data Score: 0.8713\n"
     ]
    }
   ],
   "source": [
    "svm_model = grid.best_estimator_\n",
    "print(\"Support Vector Model Results :- \")\n",
    "print(f\"Training Data Score: {round(svm_model.score(X_train, y_train),4)}\")\n",
    "print(f\"Testing Data Score: {round(svm_model.score(X_test, y_test),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.sav']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'random_forest.sav'\n",
    "joblib.dump(rf_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
